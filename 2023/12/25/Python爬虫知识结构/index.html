<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Python爬虫知识结构 | 千灵镜</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="基础知识及案例。">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫知识结构">
<meta property="og:url" content="http://yoursite.com/en/2023/12/25/Python%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84/index.html">
<meta property="og:site_name" content="千灵镜">
<meta property="og:description" content="基础知识及案例。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-12-24T16:00:00.000Z">
<meta property="article:modified_time" content="2019-12-25T09:30:24.153Z">
<meta property="article:author" content="CJ">
<meta property="article:tag" content="爬虫">
<meta property="article:tag" content="体系">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/en/atom.xml" title="千灵镜" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/en/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/en/" id="logo">千灵镜</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/en/" id="subtitle">神驰八极，心游万仞</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/en/">Home</a>
        
          <a class="main-nav-link" href="/en/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/en/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com/en"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Python爬虫知识结构" class="article article-type-post" itemscope
  itemprop="blogPost">
  <div class="article-meta">
    <a href="/en/2023/12/25/Python%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84/" class="article-date">
  <time datetime="2023-12-24T16:00:00.000Z" itemprop="datePublished">2023-12-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <header class="article-header">
      
  
    <h1 class="article-title" itemprop="name">
      Python爬虫知识结构
    </h1>
  

    </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      <!-- Table of Contents -->
      
      <p>基础知识及案例。</p>
<a id="more"></a>  
<h1 id="1-库的说明"><a href="#1-库的说明" class="headerlink" title="1. 库的说明"></a>1. 库的说明</h1><h2 id="1-1-re"><a href="#1-1-re" class="headerlink" title="1.1. re"></a>1.1. re</h2><p>Python正则表达式文档：<a href="https://docs.python.org/3/library/re.html" target="_blank" rel="noopener">https://docs.python.org/3/library/re.html</a><br>Python正则表达式的3种方法，分别是match、search和findall。</p>
<h3 id="re-match"><a href="#re-match" class="headerlink" title="re.match"></a>re.match</h3><p>re.match：从字符串起始位置匹配，有则返回re.Match object，没有则返回none。</p>
<blockquote>
<p>re.match(pattern, string, flags=0)</p>
</blockquote>
<ul>
<li>pattern：正则表达式，包含一些特殊的字符</li>
<li>string：被匹配的原字符串</li>
<li>flags：控制正则表达式的匹配方式，如是否区分大小写、多行匹配等。</li>
</ul>
<p>字符串匹配：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">m = re.match(<span class="string">'www'</span>, <span class="string">'www.santostang.com'</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"匹配的结果：  "</span>, m)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"匹配的起始与终点：  "</span>, m.span())</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"匹配的起始位置：  "</span>, m.start())</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"匹配的终点位置：  "</span>, m.end())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 得到的结果为：</span></span><br><span class="line"><span class="comment"># 匹配的结果： &lt;re.Match object; span=(0, 3), match='www'&gt;</span></span><br><span class="line"><span class="comment"># 匹配的起始与终点： (0, 3)</span></span><br><span class="line"><span class="comment"># 匹配的起始位置： 0</span></span><br><span class="line"><span class="comment"># 匹配的终点位置： 3</span></span><br></pre></td></tr></table></figure>
<p>正则匹配：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">line = <span class="string">"Fat cats are smarter than dogs, is it right? "</span></span><br><span class="line">m = re.match( <span class="string">r'(.＊) are (.＊? ) dogs'</span>, line)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'匹配的整句话'</span>, m.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'匹配的第一个结果'</span>, m.group(<span class="number">1</span>))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'匹配的第二个结果'</span>, m.group(<span class="number">2</span>))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'匹配的结果列表'</span>, m.groups())</span><br><span class="line"><span class="comment"># 得到的结果为：</span></span><br><span class="line"><span class="comment"># 匹配的整句话Fat cats are smarter than dogs</span></span><br><span class="line"><span class="comment"># 匹配的第一个结果Fat cats</span></span><br><span class="line"><span class="comment"># 匹配的第二个结果smarter than</span></span><br><span class="line"><span class="comment"># 匹配的结果列表 ('Fat cats', 'smarter than')</span></span><br></pre></td></tr></table></figure>
<p><a href="https://docs.python.org/3/library/re.html#match-objects" target="_blank" rel="noopener">https://docs.python.org/3/library/re.html#match-objects</a> </p>
<h3 id="re-search"><a href="#re-search" class="headerlink" title="re.search"></a>re.search</h3><ul>
<li>re.match只能从字符串的【起始】位置进行匹配。</li>
<li>re.search扫描整个字符串并返回【第一个】成功的匹配。</li>
<li>其他方面re.search与re.match一样。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">m_match = re.match(<span class="string">'com'</span>, <span class="string">'www.santostang.com'</span>)</span><br><span class="line">m_search = re.search(<span class="string">'com'</span>, <span class="string">'www.santostang.com'</span>)</span><br><span class="line"><span class="keyword">print</span> (m_match)</span><br><span class="line"><span class="keyword">print</span> (m_search)</span><br><span class="line"><span class="comment"># 得到结果为：</span></span><br><span class="line"><span class="comment"># None</span></span><br><span class="line"><span class="comment"># &lt;re.Match object; span=(15, 18), match='com'&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="re-findall方法"><a href="#re-findall方法" class="headerlink" title="re.findall方法"></a>re.findall方法</h3></li>
<li>match和search，只能找到一个匹配所写的模式</li>
<li>findall可以找到所有的匹配，返回列表<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">m_match = re.match(<span class="string">'[0-9]+'</span>, <span class="string">'12345 is the first number, 23456 is the sencond'</span>)</span><br><span class="line">m_search = re.search(<span class="string">'[0-9]+'</span>, <span class="string">'The first number is 12345, 23456 is the sencond'</span>)</span><br><span class="line">m_findall = re.findall(<span class="string">'[0-9]+'</span>, <span class="string">'12345 is the first number, 23456 is the sencond'</span>)</span><br><span class="line"><span class="keyword">print</span> (m_match.group())</span><br><span class="line"><span class="keyword">print</span> (m_search.group())</span><br><span class="line"><span class="keyword">print</span> (m_findall)</span><br></pre></td></tr></table></figure>
上述代码的’[0-9]+’表示任意长度的数字，然后在后面的字符串中进行匹配。<h3 id="为什么要在match的模式前加上r"><a href="#为什么要在match的模式前加上r" class="headerlink" title="为什么要在match的模式前加上r"></a>为什么要在match的模式前加上r</h3>r：raw string，纯粹的字符串。使用它就不会对引S号里面的反斜杠<code>\</code>进行特殊处理。<br>在正则表达式中有一些类似<code>\d</code>（匹配任何数字）的模式，都要进行转译。<br>假如你需要匹配文本中的字符<code>\</code>，使用编程语言表示的正则表达式里就需要4个反斜杠<code>\\\\</code>：</li>
<li>前两个反斜杠<code>\\</code>和后两个反斜杠<code>\\</code>各自在编程语言里转义成一个反斜杠<code>\</code></li>
<li>所以4个反斜杠<code>\\\\</code>就转义成了两个反斜<code>\\</code></li>
<li>这两个反斜杠<code>\\</code>最终在正则表达式里转义成一个反斜杠<code>\</code><br>Python里的原生字符串很好地解决了这个问题，在正则表达式里不会再转义，这个例子中的正则表达式可以使用r<code>\\</code>表示。</li>
</ul>
<p>(.<em>) are会尽量匹配最多的字符。贪婪模式<br>(.</em>? )会尽量匹配尽量少的字符。非贪婪模式</p>
<h2 id="1-2-bs4"><a href="#1-2-bs4" class="headerlink" title="1.2. bs4"></a>1.2. bs4</h2><p>使用BeautifulSoup解析网页<br>BeautifulSoup是一个工具箱。通过【解析文档】来提取数据。</p>
<ul>
<li>可以从HTML或XML文件中提取数据。</li>
<li>可以提供一些简单的、Python式的函数用来处理导航、搜索、修改分析树等。<br>简单，不需要多少代码就可以写出一个完整的应用程序。非常强大。<br>支持Python标准库中的HTML解析器，还支持一些第三方的解析器。</li>
</ul>
<p>BeautifulSoup 4主要特性、适合做什么、怎样使用<br>使用BeautifulSoup获取博客标题</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">link = <span class="string">"http://www.santostang.com/"</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'</span>&#125; </span><br><span class="line">r = requests.get(link, headers= headers)</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(r.text,<span class="string">"html.parser"</span>) <span class="comment"># 将网页响应体的字符串转化为soup对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;h1&gt;元素，class为' post-title'，提取&lt;a&gt;元素中的文字，strip()的功能是把字符串左右的空格去掉。find只是用来找到第一条结果。</span></span><br><span class="line">first_title = soup.find(<span class="string">"h1"</span>, class_=<span class="string">"post-title"</span>).a.text.strip() </span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"第一篇文章的标题是："</span>, first_title)</span><br><span class="line"></span><br><span class="line">title_list = soup.find_all(<span class="string">"h1"</span>, class_=<span class="string">"post-title"</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(title_list)):</span><br><span class="line">    title = title_list[i].a.text.strip()</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'第 %s 篇文章的标题是：%s'</span> %(i+<span class="number">1</span>, title))</span><br></pre></td></tr></table></figure>
<p>找所有结果，用find_all。find_all返回列表。</p>
<p>BeautifulSoup的其他功能<br>soup.prettify()  代码美化<br>首先，需要把：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">"html.parser"</span>)</span><br></pre></td></tr></table></figure>
<p>代码转化成BeautifulSoup对象。<br>BeautifulSoup对象是一个复杂的【树】形结构，它的每一个【节点】都是一个【Python对象】。</p>
<p>提取对象的3种方法：</p>
<blockquote>
<p>遍历文档树<br>搜索文档树<br>CSS选择器</p>
</blockquote>
<p>1．遍历文档树<br>先爬树干，然后小树干，最后树枝。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup.header.h3：获取取&lt;h3&gt;标签。如结果为：&lt;h3 id="name"&gt;大数据@唐松Santos&lt;/h3&gt;）。</span><br><span class="line">soup.header.div.contents：列出某个标签的所有子节点。只能获取第一代子标签。</span><br><span class="line">soup.header.div.contents[<span class="number">1</span>]：索引为<span class="number">1</span>的子标签。</span><br><span class="line">soup.header.div.children：获得所有子标签。只能获取第一代子标签。</span><br><span class="line">soup.header.div.descendants：获得所有子子孙孙标签</span><br><span class="line">soup.header.div.a.parent：获得父节点的内容：</span><br></pre></td></tr></table></figure>
<p>遍历文档树的方法其实使用得比较少。</p>
<p>2．搜索文档树<br>最常用的是搜索文档树。<br>最常用的是find()和find_all()。<br>find()和find_all()方法还可以和re正则结合起来使用</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">"^h"</span>)):  <span class="comment"># 找出所有以h开头的标签，这表示&lt;header&gt;和&lt;h3&gt;的标签都会被找到  </span></span><br><span class="line">    print(tag.name)</span><br><span class="line"><span class="comment"># 输出的结果是：</span></span><br><span class="line"><span class="comment"># header</span></span><br><span class="line"><span class="comment"># h3</span></span><br></pre></td></tr></table></figure>
<p>如果传入正则表达式作为参数，Beautiful Soup就会通过正则表达式的match()来匹配内容。</p>
<ol>
<li>CSS选择器</li>
</ol>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">通过tag标签逐层查找：soup.select("header h3")⇒得到的结果是：[<span class="tag">&lt;<span class="name">h3</span> <span class="attr">id</span>=<span class="string">"name"</span>&gt;</span>大数据@唐松Santos<span class="tag">&lt;/<span class="name">h3</span>&gt;</span>]</span><br><span class="line">通过某个tag标签下的直接子标签遍历，：</span><br><span class="line">soup.select("header &gt; h3") ⇒[<span class="tag">&lt;<span class="name">h3</span> <span class="attr">id</span>=<span class="string">"name"</span>&gt;</span>大数据@唐松Santos<span class="tag">&lt;/<span class="name">h3</span>&gt;</span>]</span><br><span class="line">soup.select("div &gt; a") ⇒ <span class="tag">&lt;<span class="name">div</span>&gt;</span>下所有的<span class="tag">&lt; <span class="attr">a</span>&gt;</span>标签</span><br><span class="line">[<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.santostang.com/feed/"</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">target</span>=<span class="string">"_blank"</span><span class="attr">title</span>=<span class="string">"RSS"</span>&gt;</span><span class="tag">&lt;<span class="name">i</span>　<span class="attr">aria-hidden</span>=<span class="string">"true"</span>　<span class="attr">class</span>=<span class="string">"fa　fa-rss"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>,　<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://weibo.com/santostang"</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">target</span>=<span class="string">"_blank"</span> <span class="attr">title</span>=<span class="string">"Weibo"</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">aria-hidden</span>=<span class="string">"true"</span> <span class="attr">class</span>=<span class="string">"fa fa-weibo"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>, …]</span><br><span class="line"></span><br><span class="line">soup.select('a[href^="http://www.santostang.com/"]')：找所有链接以http://www.santostang.com/开始的<span class="tag">&lt;<span class="name">a</span>&gt;</span>标签</span><br><span class="line">得到的结果是：</span><br><span class="line">[<span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.santostang.com/feed/"</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">target</span>=<span class="string">"_blank"</span><span class="attr">title</span>=<span class="string">"RSS"</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">aria-hidden</span>=<span class="string">"true"</span> <span class="attr">class</span>=<span class="string">"fa fa-rss"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.santostang.com/"</span>&gt;</span>首页<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.santostang.com/about-me/"</span>&gt;</span>关于我<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.santostang.com/post-search/"</span>&gt;</span>文章搜索<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://www.santostang.com/wp-login.php"</span>&gt;</span>登录<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br></pre></td></tr></table></figure>

<p>5.3 使用lxml解析网页<br>一些比较流行的解析库<br>Xpath语法（如lxml），同样是效率比较高的解析方法。lxml使用C语言编写，解析速度比不使用lxml解析器的BeautifulSoup快一些。</p>
<p>5.3.2 使用lxml获取博客标题<br>使用lxml提取网页源代码数据的3种方法<br>    XPath选择器<br>    CSS选择器<br>    BeautifulSoup的find()方法</p>
<p>和BeautifulSoup相比，lxml还多了一种XPath选择器方法。</p>
<p>XPath是一门在XML文档中查找信息的语言。<br>XPath使用路径表达式来选取XML文档中的节点或节点集，也可以用在HTML获取数据中。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">link = <span class="string">"http://www.santostang.com/"</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'</span>&#125; </span><br><span class="line">r = requests.get(link, headers= headers)</span><br><span class="line"></span><br><span class="line">html = etree.HTML(r.text) <span class="comment"># 解析为lxml的格式</span></span><br><span class="line">title_list = html.xpath(<span class="string">'//h1[@class="post-title"]/a/text()'</span>) <span class="comment"># 用XPath读取里面的内容</span></span><br><span class="line"><span class="keyword">print</span> (title_list)</span><br><span class="line"></span><br><span class="line">//：无论在文档中什么位置</span><br><span class="line">//h1：所有&lt;h1&gt;元素</span><br><span class="line">//h1[@class="post-title"]：&lt;h1&gt;中class为"post-title"的元素</span><br><span class="line">/a表示选取&lt;h1&gt;子元素的&lt;a&gt;元素</span><br><span class="line">/text()表示提取&lt;a&gt;元素中的所有文本。</span><br></pre></td></tr></table></figure>
<p>chrome审查，右键，选取元素，Copy→Copy XPath</p>
<p>5.3.3 XPath的选取方法<br>XPath使用路径表达式可以在网页源代码中选取节点，它是沿着路径来选取的，如表5-3所示。<br>XPath路径表达式及其描述 <a href="https://res.weread.qq.com/wrepub/epub_928559_47" target="_blank" rel="noopener">https://res.weread.qq.com/wrepub/epub_928559_47</a><br>下面是一个XML文档，我们将用XPath提取其中的一些数据。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="php"><span class="meta">&lt;?</span> xml version=<span class="string">"1.0"</span> encoding=<span class="string">"ISO-8859-1"</span>? &gt;</span></span><br><span class="line"><span class="php">&lt;bookstore&gt;</span></span><br><span class="line"><span class="php">    &lt;book&gt;  </span></span><br><span class="line"><span class="php">        &lt;title lang=<span class="string">"en"</span>&gt;Harry Potter&lt;/title&gt;  </span></span><br><span class="line"><span class="php">        &lt;author&gt;J K. Rowling&lt;/author&gt;  </span></span><br><span class="line"><span class="php">        &lt;year&gt;<span class="number">2005</span>&lt;/year&gt;  </span></span><br><span class="line"><span class="php">        &lt;price&gt;<span class="number">29.99</span>&lt;/price&gt;</span></span><br><span class="line"><span class="php">    &lt;/book&gt;</span></span><br><span class="line"><span class="php">&lt;/bookstore&gt;</span></span><br></pre></td></tr></table></figure>
<p>XPath的一些路径表达式及其结果：<a href="https://res.weread.qq.com/wrepub/epub_928559_48" target="_blank" rel="noopener">https://res.weread.qq.com/wrepub/epub_928559_48</a></p>
<p><a href="https://github.com/Santostang/PythonScraping/blob/master/%E7%AC%AC%E4%B8%80%E7%89%88/Cha%205%20-%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5/Cha%205%20-%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5.ipynb" target="_blank" rel="noopener">https://github.com/Santostang/PythonScraping/blob/master/%E7%AC%AC%E4%B8%80%E7%89%88/Cha%205%20-%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5/Cha%205%20-%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5.ipynb</a></p>
<p>5.5 BeautifulSoup爬虫实践：房屋价格数据<br>目的：获取安居客网站上北京二手房的数据。获取前10页二手房源的名称、价格、几房几厅、大小、建造年份、联系人、地址、标签。<br>网址：<a href="https://beijing.anjuke.com/sale/。" target="_blank" rel="noopener">https://beijing.anjuke.com/sale/。</a><br>5.5.1 网站分析</p>
<p>5.5.2 项目实践<br>通过以上分析已经能够获得各个数据所在的地址，接下来用requests加上BeautifulSoup获取安居客北京二手房结果的第一页数据，代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36'</span>&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</span><br><span class="line">    link = <span class="string">'https://beijing.anjuke.com/sale/p'</span> + str(i)</span><br><span class="line">    r = requests.get(link, headers = headers)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'现在爬取的是第'</span>, i, <span class="string">'页'</span>)</span><br><span class="line"></span><br><span class="line">    soup = BeautifulSoup(r.text, <span class="string">'lxml'</span>)</span><br><span class="line">    house_list = soup.find_all(<span class="string">'li'</span>, class_=<span class="string">"list-item"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> house <span class="keyword">in</span> house_list:</span><br><span class="line">        name = house.find(<span class="string">'div'</span>, class_ =<span class="string">'house-title'</span>).a.text.strip()</span><br><span class="line">        price = house.find(<span class="string">'span'</span>, class_=<span class="string">'price-det'</span>).text.strip()</span><br><span class="line">        price_area = house.find(<span class="string">'span'</span>, class_=<span class="string">'unit-price'</span>).text.strip()</span><br><span class="line"></span><br><span class="line">        no_room = house.find(<span class="string">'div'</span>, class_=<span class="string">'details-item'</span>).span.text</span><br><span class="line">        area = house.find(<span class="string">'div'</span>, class_=<span class="string">'details-item'</span>).contents[<span class="number">3</span>].text</span><br><span class="line">        floor = house.find(<span class="string">'div'</span>, class_=<span class="string">'details-item'</span>).contents[<span class="number">5</span>].text</span><br><span class="line">        year = house.find(<span class="string">'div'</span>, class_=<span class="string">'details-item'</span>).contents[<span class="number">7</span>].text</span><br><span class="line">        broker = house.find(<span class="string">'span'</span>, class_=<span class="string">'brokername'</span>).text</span><br><span class="line">        broker = broker[<span class="number">1</span>:]</span><br><span class="line">        address = house.find(<span class="string">'span'</span>, class_=<span class="string">'comm-address'</span>).text.strip()</span><br><span class="line">        address = address.replace(<span class="string">'\xa0\xa0\n                    '</span>,<span class="string">'  '</span>)</span><br><span class="line">        tag_list = house.find_all(<span class="string">'span'</span>, class_=<span class="string">'item-tags'</span>)</span><br><span class="line">        tags = [i.text <span class="keyword">for</span> i <span class="keyword">in</span> tag_list] </span><br><span class="line">        <span class="keyword">print</span> (name, price, price_area, no_room, area, floor, year, broker, address, tags)</span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line">```  </span><br><span class="line">进阶：获取其中的各项数据，如小区名称、房屋类型、房屋朝向、参考首付等。</span><br><span class="line"></span><br><span class="line">https://github.com/Santostang/PythonScraping/blob/master/%E7%AC%AC%E4%B8%<span class="number">80</span>%E7%<span class="number">89</span>%<span class="number">88</span>/Cha%<span class="number">205</span>%<span class="number">20</span>-%E8%A7%A3%E6%<span class="number">9</span>E%<span class="number">90</span>%E7%BD%<span class="number">91</span>%E9%A1%B5/Cha%<span class="number">205</span>%<span class="number">20</span>_%E7%AB%A0%E6%<span class="number">9</span>C%AB%E5%AE%<span class="number">9</span>E%E6%<span class="number">88</span>%<span class="number">98.</span>ipynb</span><br><span class="line"><span class="comment">### 1.2.1. requests  </span></span><br><span class="line">```py  </span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">'http://www.santostang.com/'</span>)  </span><br><span class="line"><span class="comment"># ========【r的方法】========  </span></span><br><span class="line"><span class="comment"># r response响应对象，存储了服务器响应的内容，以从中获取需要的信息  </span></span><br><span class="line"><span class="comment"># r.encoding  服务器内容使用的文本编码。  </span></span><br><span class="line"><span class="comment"># r.status_code 响应状态码。检测请求是否正确响应。  </span></span><br><span class="line"><span class="comment"># r.text  字符串方式的响应体。会自动根据响应头部的字符编码进行解码。  </span></span><br><span class="line"><span class="comment"># r.content 字节方式的响应体。会自动解码gzip和deflate编码的响应数据。gzip文件用这个。  </span></span><br><span class="line"><span class="comment"># r.json()  Requests中内置的JSON解码器。  </span></span><br><span class="line"><span class="comment"># r.url r对应的请求的页面网址  </span></span><br><span class="line"><span class="comment"># ========【requests.get的参数设置】========  </span></span><br><span class="line"><span class="comment">## URL参数、请求头、发送POST请求、设置超时  </span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ----------【params】：dict ----------  </span></span><br><span class="line"><span class="comment">### get传递url参数。http://httpbin.org/get?key1=value1&amp;key2=value2  </span></span><br><span class="line">key_dict = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;  </span><br><span class="line">r = requests.get(<span class="string">'http://httpbin.org/get'</span>, params=key_dict)  </span><br><span class="line"><span class="comment">## ----------【headers】：dict ----------  </span></span><br><span class="line"><span class="comment">### 有的网站不带请求头会返回错误的数据。带请求头使程序更像人的手动行为  </span></span><br><span class="line">headers = &#123;  </span><br><span class="line"><span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.82 Safari/537.36'</span>,  </span><br><span class="line"><span class="string">'Host'</span>: <span class="string">'www.santostang.com'</span>  </span><br><span class="line">&#125;  </span><br><span class="line">r = requests.get(<span class="string">'http://www.santostang.com/'</span>, headers=headers)  </span><br><span class="line"><span class="comment">## ----------【data】: dict ----------  </span></span><br><span class="line"><span class="comment">### 用于提交表单。data在发出请求的时候会自动编码为表单形式。  </span></span><br><span class="line">key_dict = &#123;<span class="string">'key1'</span>: <span class="string">'value1'</span>, <span class="string">'key2'</span>: <span class="string">'value2'</span>&#125;  </span><br><span class="line">r = requests.post(<span class="string">'http://httpbin.org/post'</span>, data=key_dict)  </span><br><span class="line"><span class="comment">## ----------【timeout】: 单位为秒 ----------  </span></span><br><span class="line"><span class="comment">### 如果服务器在timeout秒内没有应答，就返回异常。一般会把这个值设置为20秒。  </span></span><br><span class="line">link = <span class="string">"http://www.santostang.com/"</span>  </span><br><span class="line">r = requests.get(link, timeout= <span class="number">0.001</span>)  </span><br><span class="line"><span class="comment">## 返回的异常为：  </span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ConnectTimeout: HTTPConnectionPool(host='www.santostang.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(&lt;requests.packages.urllib3.connection.HTTPConnection object at 0x00000000077806D8&gt;, 'Connection to www.santostang.com timed out. (connect timeout=0.001)'))  </span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 异常值的意思是，时间限制在0.001秒内，连接到地址为www.santostang.com的时间已到。  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># https://github.com/Santostang/PythonScraping/blob/master/第一版/Cha 3 -静态网页抓取/Cha 3 -静态网页抓取.ipynb  </span></span><br><span class="line">```  </span><br><span class="line"><span class="comment">### 1.2.2. Selenium  </span></span><br><span class="line">Selenium选择元素的方法有很多。  </span><br><span class="line">xpath和css_selector是比较好的方法，一方面比较清晰，另一方面相对其他方法定位元素比较准确。  </span><br><span class="line">```xpath</span><br><span class="line">查找单个元素：  </span><br><span class="line">find_element_by_class_name：<span class="class"><span class="keyword">class</span>选择  </span></span><br><span class="line">    如&lt;p class="content"&gt;Site content goes here.&lt;/p&gt;⇒driver.find_element_by_class_name('content')。  </span><br><span class="line">find_element_by_css_selector：<span class="class"><span class="keyword">class</span>选择  </span></span><br><span class="line">    如&lt;div class='bdy-inner'&gt;test&lt;/div&gt;⇒driver.find_element_by_css_selector ('div.bdy-inner')。  </span><br><span class="line">find_element_by_id：id选择  </span><br><span class="line">    如&lt;div id='bdy-inner'&gt;test&lt;/div&gt;⇒driver.find_element_by_id('bdy-inner')。  </span><br><span class="line">find_element_by_link_text：链接地址选择  </span><br><span class="line">    如&lt;a href="continue.html"&gt;Continue&lt;/a&gt;⇒driver.find_element_by_link_text('Continue')。  </span><br><span class="line">find_element_by_name：name选择  </span><br><span class="line">    如&lt;input name=<span class="string">"username"</span>type=<span class="string">"text"</span> /&gt;⇒driver.find_element_by_name(<span class="string">'username'</span>)。  </span><br><span class="line">find_element_by_partial_link_text：链接的部分地址选择  </span><br><span class="line">    如 &lt;a href="continue.html"&gt;Continue&lt;/a&gt;⇒driver.find_element_by_partial_link_text('Conti')。  </span><br><span class="line">find_element_by_tag_name：名称选择  </span><br><span class="line">    如&lt;h1&gt;Welcome&lt;/h1&gt;⇒driver.find_element_by_tag_name('h1')。  </span><br><span class="line">find_element_by_xpath：通过xpath选择  </span><br><span class="line">    如&lt;form id=<span class="string">"loginForm"</span>&gt; ⇒driver.find_element_by_xpath(<span class="string">"//form[@id='loginForm']"</span>)。  </span><br><span class="line"></span><br><span class="line">查找多个元素时，[element]后加上s：  </span><br><span class="line">find_elements_by_class_name  </span><br><span class="line">find_elements_by_css_selector  </span><br><span class="line">find_elements_by_link_text  </span><br><span class="line">find_elements_by_name  </span><br><span class="line">find_elements_by_partial_link_text  </span><br><span class="line">find_elements_by_tag_name  </span><br><span class="line">find_elements_by_xpath  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">除了Selenium的click操作元素方法，常见的操作元素方法：  </span><br><span class="line">● Clear清除元素的内容。  </span><br><span class="line">● send_keys模拟按键输入。  </span><br><span class="line">● Click单击元素。  </span><br><span class="line">● Submit提交表单。</span><br></pre></td></tr></table></figure>
<p>comment = driver.find_element_by_css_selector(‘div.bdy-inner’)<br>content = comment.find_element_by_tag_name(‘p’) </p>
<p>Selenium的高级操作：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fp = webdriver.FirefoxProfile()</span><br><span class="line"><span class="comment"># 1. 限制CSS的页面</span></span><br><span class="line">fp.set_preference(<span class="string">"permissions.default.stylesheet"</span>,<span class="number">2</span>) </span><br><span class="line"><span class="comment"># 2. 限制图片的显示。极大地提高网络爬虫的效率。图片文件相对于文字、CSS、JavaScript等文件都比较大，加载需要较长时间。</span></span><br><span class="line">fp.set_preference(<span class="string">"permissions.default.image"</span>,<span class="number">2</span>) </span><br><span class="line"><span class="comment"># 3. 控制JavaScript的运行。大多数网页都会利用JavaScript异步加载很多内容，如果这些内容不是需要的，其加载会浪费时间。</span></span><br><span class="line">fp.set_preference(<span class="string">"javascript.enabled"</span>, <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>全部限制对于加载速度的提升效果最好。如果能够限制，那么最好限制多种加载，这样的效果最好。<br>具体的加载速度提升还得看相应的网页，若网页的图片比较多，则限制图片的加载肯定效果很好。</p>
<p>参考链接：<a href="https://github.com/Santostang/PythonScraping/blob/master/%E7%AC%AC%E4%B8%80%E7%89%88/Cha%204%20-%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96/Cha%204%20-%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96.ipynb" target="_blank" rel="noopener">selenium</a></p>
<h1 id="2-典型应用"><a href="#2-典型应用" class="headerlink" title="2. 典型应用"></a>2. 典型应用</h1><h3 id="2-0-3-简单的爬虫"><a href="#2-0-3-简单的爬虫" class="headerlink" title="2.0.3. 简单的爬虫"></a>2.0.3. 简单的爬虫</h3><p>【用到的库】requests + bs4  </p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/Santostang/PythonScraping/blob/master/第一版/Cha 2 - 编写你的第一个网络爬虫/Cha 2 _章末实战.ipynb  </span></span><br><span class="line"><span class="comment">#!/usr/bin/python  </span></span><br><span class="line"><span class="comment"># coding: utf-8  </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup   <span class="comment">#从bs4这个库中导入BeautifulSoup  </span></span><br><span class="line"><span class="comment"># 第一步：获取页面  </span></span><br><span class="line">link = <span class="string">"http://www.santostang.com/"</span>  </span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'</span>&#125;  </span><br><span class="line">r = requests.get(link, headers= headers) <span class="comment"># requests的headers伪装成浏览器访问。r是requests的Response回复对象。  </span></span><br><span class="line"><span class="comment"># 第二步：提取需要的数据  </span></span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">"html.parser"</span>)      <span class="comment"># 使用BeautifulSoup解析这段网页。把HTML代码转化为soup对象。r.text是获取的网页内容代码  </span></span><br><span class="line">title = soup.find(<span class="string">"h1"</span>, class_=<span class="string">"post-title"</span>).a.text.strip() <span class="comment"># 提取第一篇文章的标题  </span></span><br><span class="line"><span class="keyword">print</span> (title)  </span><br><span class="line"><span class="comment"># 第三步：存储数据  </span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'title_test.txt'</span>, <span class="string">"a+"</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    f.write(title)  </span><br><span class="line">    </span><br><span class="line">```  </span><br><span class="line"><span class="comment">### 2.0.4. 爬取豆瓣电影TOP250  </span></span><br><span class="line">【用到的库】requests + bs4  </span><br><span class="line">获取豆瓣电影TOP250的所有电影的名称  </span><br><span class="line">网页地址为：https://movie.douban.com/top250  </span><br><span class="line">第一页有<span class="number">25</span>个电影  </span><br><span class="line">获取所有的<span class="number">250</span>页电影  </span><br><span class="line">总共<span class="number">10</span>页的内容  </span><br><span class="line">第二页：https://movie.douban.com/top250? start=25  </span><br><span class="line">第三页：https://movie.douban.com/top250? start=50  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```py  </span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movies</span><span class="params">()</span>:</span>  </span><br><span class="line">    headers = &#123;  </span><br><span class="line">    <span class="string">'user-agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.82 Safari/537.36'</span>,  </span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'movie.douban.com'</span>  </span><br><span class="line">    &#125;  </span><br><span class="line">    movie_list = []  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>):  </span><br><span class="line">        link = <span class="string">'https://movie.douban.com/top250?start='</span> + str(i * <span class="number">25</span>)  </span><br><span class="line">        r = requests.get(link, headers=headers, timeout= <span class="number">10</span>)  </span><br><span class="line">        <span class="keyword">print</span> (str(i+<span class="number">1</span>),<span class="string">"页响应状态码:"</span>, r.status_code)  </span><br><span class="line">   </span><br><span class="line">        soup = BeautifulSoup(r.text, <span class="string">"lxml"</span>)  </span><br><span class="line">        div_list = soup.find_all(<span class="string">'div'</span>, class_=<span class="string">'hd'</span>)  </span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> div_list:  </span><br><span class="line">            movie = each.a.span.text.strip()  </span><br><span class="line">            movie_list.append(movie)  </span><br><span class="line">    <span class="keyword">return</span> movie_list  </span><br><span class="line">   </span><br><span class="line">movies = get_movies()  </span><br><span class="line"><span class="keyword">print</span> (movies)  </span><br><span class="line"><span class="comment"># 原文有误  </span></span><br><span class="line"><span class="comment"># 用 ]: 便于在 ipynb 中查找下一项  </span></span><br><span class="line">```  </span><br><span class="line">参考链接：豆瓣电影(https://github.com/Santostang/PythonScraping/blob/master/第一版/Cha <span class="number">3</span> -静态网页抓取/Cha <span class="number">3</span> _章末实战.ipy)  </span><br><span class="line"></span><br><span class="line">进阶问题：获取TOP <span class="number">250</span>电影的英文名、港台名、导演、主演、上映年份、电影分类以及评分。  </span><br><span class="line"><span class="comment">### 2.0.5. 爬取动态网页  </span></span><br><span class="line">【用到的库】requests + json  </span><br><span class="line">AJAX加载的动态网页，有两种爬取方法：  </span><br><span class="line">（<span class="number">1</span>）通过浏览器审查元素解析地址。  </span><br><span class="line">（<span class="number">2</span>）通过Selenium模拟浏览器抓取。  </span><br><span class="line"></span><br><span class="line">两个特别重要的变量，即offset和limit。  </span><br><span class="line">limit：每一页评论数量的最大值  </span><br><span class="line">offset：本页的第一条评论是总的第几条  </span><br><span class="line"></span><br><span class="line">```py  </span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">import</span> json  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single_page_comment</span><span class="params">(link)</span>:</span>  </span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span> : <span class="string">'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'</span>&#125;  </span><br><span class="line">    r = requests.get(link, headers= headers)  </span><br><span class="line">    <span class="comment"># 获取 json 的 string  </span></span><br><span class="line">    json_string = r.text  </span><br><span class="line">    json_string = json_string[json_string.find(<span class="string">'&#123;'</span>):<span class="number">-2</span>]  </span><br><span class="line">    json_data = json.loads(json_string) <span class="comment"># 使用json.loads()把字符串格式的响应体数据转化为json数据  </span></span><br><span class="line">    comment_list = json_data[<span class="string">'results'</span>][<span class="string">'parents'</span>] <span class="comment"># json数据的结构提取  </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> eachone <span class="keyword">in</span> comment_list:  </span><br><span class="line">        message = eachone[<span class="string">'content'</span>]  </span><br><span class="line">        <span class="keyword">print</span> (message)  </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>):  </span><br><span class="line">    link1 = <span class="string">"https://api-zero.livere.com/v1/comments/list?callback=jQuery112407875296433383039_1506267778283&amp;limit=10&amp;offset="</span>  </span><br><span class="line">    link2 = <span class="string">"&amp;repSeq=3871836&amp;requestPath=%2Fv1%2Fcomments%2Flist&amp;consumerSeq=1020&amp;livereSeq=28583&amp;smartloginSeq=5154&amp;_=1506267778285"</span>  </span><br><span class="line">    page_str = str(page)  </span><br><span class="line">    link = link1 + page_str + link2  </span><br><span class="line">    <span class="keyword">print</span> (link)  </span><br><span class="line">    single_page_comment(link)  </span><br><span class="line">```  </span><br><span class="line">参考链接：  </span><br><span class="line">https://github.com/Santostang/PythonScraping/blob/master/第一版/Cha <span class="number">4</span> -动态网页抓取/Cha <span class="number">4</span> -动态网页抓取.ipynb  </span><br><span class="line"><span class="comment">### 2.0.6. 通过Selenium模拟浏览器抓取  </span></span><br><span class="line">```py</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">"https://www.dianping.com/search/category/7/10/p1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果运行之后，发现程序报错：</span></span><br><span class="line"><span class="comment">#     selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH.</span></span><br><span class="line"><span class="comment"># 可以到https://github.com/mozilla/geckodriver/releases下载最新版的geckodriver，解压后可以放在Python安装目录（可能是Script子文件夹）下（可能需并放在环境变量的PATH中）。</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.firefox.firefox_binary <span class="keyword">import</span> FirefoxBinary   </span><br><span class="line">caps = webdriver.DesiredCapabilities().FIREFOX</span><br><span class="line">caps[<span class="string">"marionette"</span>] = <span class="literal">False</span></span><br><span class="line">   </span><br><span class="line">path =  <span class="string">r'D:\\Program Files\\Mozilla Firefox\\firefox.exe'</span></span><br><span class="line">binary = FirefoxBinary(path) <span class="comment"># Firefox程序的地址  </span></span><br><span class="line">driver = webdriver.Firefox(firefox_binary=binary, capabilities=caps)</span><br><span class="line">driver.get(<span class="string">"http://www.santostang.com/2017/03/02/hello-world/"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    load_more = driver.find_element_by_css_selector(<span class="string">'div.tie-load-more'</span>)   <span class="comment"># 更多或下一页</span></span><br><span class="line">    load_more.click()            <span class="comment"># 模拟单击</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="keyword">pass</span>    </span><br><span class="line">comments = driver.find_elements_by_css_selector(<span class="string">'div.bdy- inner'</span>) </span><br><span class="line">time.sleep(<span class="number">5</span>)  </span><br><span class="line"></span><br><span class="line">user = driver.find_element_by_name(<span class="string">"username"</span>)  <span class="comment">#找到用户名输入框</span></span><br><span class="line">user.clear  <span class="comment">#清除用户名输入框内容</span></span><br><span class="line">user.send_keys(<span class="string">"1234567"</span>)  <span class="comment">#在框中输入用户名</span></span><br><span class="line">pwd = driver.find_element_by_name(<span class="string">"password"</span>)  <span class="comment">#找到密码输入框</span></span><br><span class="line">pwd.clear  <span class="comment">#清除密码输入框内容</span></span><br><span class="line">pwd.send_keys(<span class="string">"＊＊＊＊＊＊"</span>)    <span class="comment">#在框中输入密码</span></span><br><span class="line">driver.find_element_by_id(<span class="string">"loginBtn"</span>).click()  <span class="comment">#单击登录</span></span><br></pre></td></tr></table></figure>
<h3 id="2-0-7-深圳短租"><a href="#2-0-7-深圳短租" class="headerlink" title="2.0.7. 深圳短租"></a>2.0.7. 深圳短租</h3><p>目的：获取Airbnb深圳前20页的短租房源的名称、价格、评价数量、房屋类型、床数量和房客数量。监控和了解竞争对手的房屋名称和价格，让自己的房子有竞争力。<br>网址：<a href="https://zh.airbnb.com/s/Shenzhen--China?page=1" target="_blank" rel="noopener">https://zh.airbnb.com/s/Shenzhen--China?page=1</a></p>
<p>4.4.1 网站分析</p>
<p>一个房子的所有数据。地址为：div.infoContainer_v72lrv。<br>价格数据，地址为：div.priceContainer_4ml1ll<br>评价数据，地址为：span.text_5mbkop-o_O-size_micro_16wifzf-o_O-inline_g86r3e<br>房屋名称数据，地址为：div.listingNameContainer_kq7ac0-o_O-ellipsized_1iurgbx<br>房间类型、床数量和房客数量，地址为：span.detailWithoutWrap_j1kt73</p>
<p>4.4.2 项目实践<br>用Selenium获取Airbnb第一页的数据。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.firefox.firefox_binary <span class="keyword">import</span> FirefoxBinary</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">caps = webdriver.DesiredCapabilities().FIREFOX</span><br><span class="line">caps[<span class="string">"marionette"</span>] = <span class="literal">True</span></span><br><span class="line">binary = FirefoxBinary(<span class="string">r'C:\Program Files\Firefox Developer Edition\firefox.exe'</span>)</span><br><span class="line"><span class="comment"># 把上述地址改成你电脑中Firefox程序的地址 </span></span><br><span class="line"><span class="comment"># 如果没改，会出现selenium.common.exceptions.SessionNotCreatedException: Message: Unable to find a matching set of capabilities</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#用 selenium 的 driver 来启动 firefox</span></span><br><span class="line">driver = webdriver.Firefox(firefox_binary=binary, capabilities=caps)</span><br><span class="line"><span class="comment">#在虚拟浏览器中打开 Airbnb 页面。使用Selenium打开该页面</span></span><br><span class="line">driver.get(<span class="string">"https://zh.airbnb.com/s/Shenzhen--China?page=1"</span>)</span><br><span class="line"></span><br><span class="line">time.sleep(<span class="number">20</span>)</span><br><span class="line"><span class="comment">#找到页面中所有的出租房。用Selenium的css selector获取所有房屋的div数据</span></span><br><span class="line">rent_list = driver.find_elements_by_css_selector(<span class="string">'div._1788tsr0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#对于每一个出租房</span></span><br><span class="line"><span class="keyword">for</span> eachhouse <span class="keyword">in</span> rent_list:</span><br><span class="line">    <span class="comment">#找到评论数量</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        comment = eachhouse.find_element_by_css_selector(<span class="string">'span._gb7fydm'</span>)</span><br><span class="line">        comment = comment.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        comment = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#找到价格</span></span><br><span class="line">    price = eachhouse.find_element_by_css_selector(<span class="string">'span._hylizj6'</span>)</span><br><span class="line">    price = price.text[<span class="number">4</span>:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#找到名称</span></span><br><span class="line">    name = eachhouse.find_element_by_css_selector(<span class="string">'div._ew0cqip'</span>)</span><br><span class="line">    name = name.text</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#找到房屋类型，大小</span></span><br><span class="line">    details = eachhouse.find_elements_by_css_selector(<span class="string">'div._saba1yg small div span'</span>)</span><br><span class="line">    details = details[<span class="number">0</span>].text</span><br><span class="line">    house_type = details.split(<span class="string">" · "</span>)[<span class="number">0</span>]</span><br><span class="line">    bed_number = details.split(<span class="string">" · "</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">print</span> (comment, price, name, house_type, bed_number)</span><br></pre></td></tr></table></figure>
<p>进阶：将Selenium的控制CSS加载、控制图片加载和控制JavaScript加载加入本实践项目的代码中，从而提升爬虫的速度。</p>
<p><a href="https://github.com/Santostang/PythonScraping/blob/master/%E7%AC%AC%E4%B8%80%E7%89%88/Cha%204%20-%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96/Cha%204%20_%E7%AB%A0%E6%9C%AB%E5%AE%9E%E6%88%98.ipynb" target="_blank" rel="noopener">https://github.com/Santostang/PythonScraping/blob/master/%E7%AC%AC%E4%B8%80%E7%89%88/Cha%204%20-%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96/Cha%204%20_%E7%AB%A0%E6%9C%AB%E5%AE%9E%E6%88%98.ipynb</a></p>
<h1 id="3-工具及资源列表"><a href="#3-工具及资源列表" class="headerlink" title="3. 工具及资源列表"></a>3. 工具及资源列表</h1><h2 id="3-1-网络下载"><a href="#3-1-网络下载" class="headerlink" title="3.1. 网络下载"></a>3.1. 网络下载</h2><p>Anaconda： <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">https://www.continuum.io/downloads</a> 。<br>Robomongo：MongoDB数据库的可视化管理工具。<br>Redis Desktop Manager：Redis的可视化管理工具。  </p>
<ul>
<li>下载 <a href="https://redisdesktop.com/download" target="_blank" rel="noopener">https://redisdesktop.com/download</a>  </li>
<li>界面 <a href="https://res.weread.qq.com/wrepub/epub_928559_154" target="_blank" rel="noopener">https://res.weread.qq.com/wrepub/epub_928559_154</a>  </li>
</ul>
<p>Alt + Enter jupyter快捷键  </p>
<h2 id="3-2-书籍辅助"><a href="#3-2-书籍辅助" class="headerlink" title="3.2. 书籍辅助"></a>3.2. 书籍辅助</h2><ul>
<li>Python网络爬虫从入门到实践，唐松  </li>
</ul>
<ul>
<li>Github：<a href="https://github.com/Santostang/PythonScraping" target="_blank" rel="noopener">https://github.com/Santostang/PythonScraping</a><br>百度网：<a href="http://pan.baidu.com/s/1c2w9rck" target="_blank" rel="noopener">http://pan.baidu.com/s/1c2w9rck</a><br>书本对应的Python网络爬虫的教学:<a href="http://www.santostang.com" target="_blank" rel="noopener">www.santostang.com</a><br>网站不会更改设计和框架，本书的网络爬虫代码可以一直使用<br>作者自己的博客网站，可以避免一些法律上的风险  <h2 id="3-3-端口"><a href="#3-3-端口" class="headerlink" title="3.3. 端口"></a>3.3. 端口</h2>jupyter：8888  <h1 id="4-库"><a href="#4-库" class="headerlink" title="4. 库"></a>4. 库</h1><h2 id="4-1-Python第三方库"><a href="#4-1-Python第三方库" class="headerlink" title="4.1. Python第三方库"></a>4.1. Python第三方库</h2>基本格式：（安装时，把name替换为要安装的第三方库）  </li>
<li><code>pip install name</code>  </li>
<li><code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple name</code>  </li>
</ul>
<ul>
<li>科学计算的包，如Numpy、Scipy、Pandas和Matplotlib。  </li>
<li>机器学习、生物医学和天体物理学计算，如Scikit-Learn、BioPython。  </li>
<li>获取网页：requests、urllib、selenium  </li>
<li>解析数据：lxml、bs4的BeautifulSoup、re(标准库)  </li>
<li>存储数据：MySQL、MongoDB  <h1 id="5-附录"><a href="#5-附录" class="headerlink" title="5. 附录"></a>5. 附录</h1><h1 id="6-单项分析"><a href="#6-单项分析" class="headerlink" title="6. 单项分析"></a>6. 单项分析</h1><h2 id="6-1-是什么"><a href="#6-1-是什么" class="headerlink" title="6.1. 是什么"></a>6.1. 是什么</h2>Anaconda：Python开发集成环境。南美洲的巨蟒。自带Python、pip和Jupyter。<br>第三方库：可理解为供用户调用的代码组合。在安装某个库之后，可以直接调用其中的功能，使得我们不用一个代码一个代码地实现某个功能。<br>DT（Data Technology，数据技术）  </li>
</ul>
<p>命令提示符。输入一些命令后，可执行对系统的管理。 Windows的cmd，开始按钮→cmd。Mac的terminal。应用程序→terminal。<br>爬虫：<br>pip：Python安装各种第三方库（package）的工具。<br>Python：蟒蛇<br>数据交换：网站与用户的沟通本质。  </p>
<p>print<br>代码缩进：代码要按照结构以Tab键或者4个空格进行缩进严格缩进<br>注释：#  </p>
<p>Python不需要在使用之前声明需要使用的变量和类别。<br>字符串（string）：单引号（’）或双引号（”）<br>连接字符串: +  </p>
<p>数字（Number）：数字用来存储数值<br>整数（int）<br>浮点数（float）：由整数和小数部分组成。  </p>
<p>列表（list）:能够包含任意种类的数据类型和任意数量。<br>创建列表非常容易，只要把不同的变量放入方括号中，并用逗号分隔即可，例如list0 = [“a”,2,”c”,4]<br>增删查改、索引、切片<br>字典（Dictionaries）：一种可变容器模型。<br>键（key）和值（value）。key必须唯一，但是值不用。值也可以取任何数据类型。<br>遍历<br>条件语句：满足条件的时候才执行某部分代码。条件为布尔值，也就是只有True和False两个值。<br>    当if判断条件成立时才执行后面的语句；当条件不成立的时候，执行else后面的语句<br>    如果需要判断的有多种条件，就需要用到elif<br>无序：字典<br>有序：列表、元组<br>对象有两种，即可更改（mutable）与不可更改（immutable）对象。在Python中，strings、tuples和numbers是不可更改对象，而list、dict等是可更改对象。  </p>
<p>循环语句：多次执行一个代码片段。<br>循环分为for循环和while循环。<br>for循环：在一个给定的顺序下重复执行。<br>while循环：不断重复执行，只要能满足一定条件。  </p>
<p>函数<br>代码庞大复杂时，使得代码易读，可重复使用，并且容易调整顺序。<br>函数的参数与返回值  </p>
<p>面向过程编程：根据业务逻辑从上到下写代码，最容易被初学者接受。<br>函数式编程：把某些功能封装到函数中，需要用时可以直接调用，不用重复撰写。函数式的编程方法节省了大量时间。只需要写清楚输入和输出变量并执行函数即可。<br>面向对象编程：把函数进行分类和封装后放入对象中，使得开发更快、更强。首先要创建封装对象，然后还要通过对象调用被封装的内容。在某些应用场景下，面向对象编程能够显示出更大的优势。<br>如果各个函数之间独立且无共用的数据，就选用函数式编程；如果各个函数之间有一定的关联性，选用面向对象编程比较好。<br>特性与行为，属性和方法<br>面向对象的两大特性：封装和继承。<br>封装：把内容封装好，再调用封装好的内容。使用构造方法将内容封装到对象中，然后通过对象直接或self间接获取被封装的内容。<br>继承：以普通的类为基础建立专门的类对象。子继承了父的某些特性。将多个类共有的方法提取到父类中，子类继承父类中的方法即可，不必一一实现每个方法。  </p>
<p>【状态码】<br>200，请求成功<br>4xx，客户端错误<br>5xx，服务器错误<br>【请求头】<br>Headers：提供了关于请求、响应或其他发送实体的信息。<br>如果没有指定请求头或请求的请求头和实际网页不一致，就可能无法返回正确的结果。  </p>
<p>Chrome浏览器的检查。单击需要请求的网页，在Headers中可以看到Requests Headers的详细信息。  </p>
<p>请求头的信息为：<br>GET / HTTP/1.1<br>Host: <a href="http://www.santostang.com" target="_blank" rel="noopener">www.santostang.com</a><br>Connection: keep-alive<br>Upgrade-Insecure-Requests: 1<br>User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36<br>Accept:<br>text/html, application/xhtml+xml, application/xml; q=0.9, image/webp, <em>/</em>; q=0.8 Accept-Encoding: gzip, deflate, sdch<br>Accept-Language: en-US, en; q=0.8, zh-CN; q=0.6, zh; q=0.4, zh-TW; q=0.2  </p>
<p>GET请求，密码会显示在URL中，非常不安全。<br>POST请求，<br>【动态网页】<br>AJAX（Asynchronous Javascript And XML，异步JavaScript和XML），一种异步更新技术。<br>单击“更多”，url地址没有任何改变，有新内容加载出来。<br>数据不会出现在网页源代码中。但是有JavaScript代码。<br>最后呈现出来的数据是通过JavaScript加载的。  </p>
<p>通过在后台与服务器进行少量数据交换就可以使网页实现异步更新。<br>在不重新加载整个网页的情况下对网页的某部分进行更新。<br>减少了网页重复内容的下载<br>节省了流量<br>更小、更快、更友好  </p>
<p>传统的网页必须重载整个网页页面  </p>
<p>动态网页的例子<br><a href="http://www.santostang.com/2018/07/04/hello-world/" target="_blank" rel="noopener">http://www.santostang.com/2018/07/04/hello-world/</a>  </p>
<p>页面下面的评论用JavaScript加载。评论数据没法在在网页源代码找到。  </p>
<h3 id="6-1-1-Selenium"><a href="#6-1-1-Selenium" class="headerlink" title="6.1.1. Selenium"></a>6.1.1. Selenium</h3><p>Selenium官方文档：<a href="http://selenium-python.readthedocs.io/index.html。" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/index.html。</a>  </p>
<p>Selenium要在整个网页加载出来后才开始爬取内容，速度往往较慢。  </p>
<p>Selenium可以实现的功能：<br>操作元素对浏览器中的网页进行各种操作，包括登录。<br>模拟鼠标单击、双击、拖拽<br>获得网页中各个元素的大小<br>模拟键盘<br>浏览器渲染引擎。直接用浏览器在显示网页时解析HTML、应用CSS样式并执行JavaScript的语句。Selenium使用浏览器渲染，数据已经渲染到了HTML代码中。用chrome定位标签即可。<br>用脚本控制浏览器操作。Python的Selenium库模拟浏览器完成抓取。<br>Selenium：用于Web应用程序测试的工具。Selenium测试直接运行在浏览器中，浏览器自动按照脚本代码做出单击、输入、打开、验证等操作，就像真正的用户在操作一样。</p>
<p>用Selenium控制浏览器加载的内容，可加快Selenium的爬取速度。此类常用的方法有：<br>（1）控制CSS的加载。<br>（2）控制图片文件的显示。<br>（3）控制JavaScript的运行。<br>（1）控制CSS。因为抓取过程中仅仅抓取页面的内容，CSS样式文件是用来控制页面的外观和元素放置位置的，对内容并没有影响，所以我们可以限制网页加载CSS，从而减少抓取时间。  </p>
<p>支持多个浏览器的调用：IE（7、8、9、10、11）、Firefox、Safari、Google Chrome、Opera等。最常用的是Firefox。</p>
<h3 id="6-1-2-正则表达式"><a href="#6-1-2-正则表达式" class="headerlink" title="6.1.2. 正则表达式"></a>6.1.2. 正则表达式</h3><p>元字符：<a href="https://res.weread.qq.com/wrepub/epub_928559_43" target="_blank" rel="noopener">https://res.weread.qq.com/wrepub/epub_928559_43</a> 问加合星<br><a href="https://regex101.com/" target="_blank" rel="noopener">https://regex101.com/</a><br>正则表达式：字符串操作的逻辑公式。用事先定义好的特定字符组合成规则字符串，用该规则字符串来过滤字符串。<br>正则表达式可以迅速地用极简单的方式达到字符串的复杂控制。</p>
<h2 id="6-2-为什么"><a href="#6-2-为什么" class="headerlink" title="6.2. 为什么"></a>6.2. 为什么</h2><p>为什么、好处、重要性、作用、意义、优势、不足、历史、现状、趋势、大背景。  </p>
<h3 id="6-2-1-大数据及爬虫"><a href="#6-2-1-大数据及爬虫" class="headerlink" title="6.2.1. 大数据及爬虫"></a>6.2.1. 大数据及爬虫</h3><p>技术创新驱动变革的潮流。<br>数据量爆发式增长的互联网时代。<br>大数据分析的火热。<br>大数据成为业界与学术界最火热的话题之一。<br>数据已经成为每个公司极为重要的资产。<br>互联网大量的公开数据为个人和公司提供了以往想象不到的可以获取的数据量。<br>网络爬虫技术是大数据分析的第一环。有助于获取有用的公开数据集。<br>理解了信息的获取、存储和整理，才有可能系统地收集和应用不同源头和千变万化的网站信息。<br>DT的核心是从信息的源头去理解和分析，以做出能打动对方的行动决策方案。<br>由谷歌搜索到现在的大数据时代，爬虫技术的重要性和广泛性一直很突出。<br>爬取目标网站的资料、分析和建立应用。 获取数据自动、实时、及时、省时。<br>电商市场的重要性日益凸显。了解对手的产品特点、价格以及销量情况，及时跟进产品开发进度和营销策略，从而知己知彼，赢得竞争。过去，两个痛点——无法自动化和无法实时获取。产品研发部门会手动访问一个个电商产品页面，人工复制并粘贴到Excel表格中，制作竞品分析报告。但是这种重复性的手动工作不仅浪费宝贵的时间，一不留神复制少了一个数字还会导致数据错误；对手产品的销量则是由某一家咨询公司提供报告，每周一次，但是报告缺乏实时性，难以针对快速多变的市场及时调整价格和营销策略。<br>学会一项新的技术<br>第一方企业（也就是拥有这些数据的企业）做出更好的决策<br>第三方企业也可从中受益<br>数据共享<br>Python：热门的开源软件（这意味着有人源源不断地开发更新且更强大的包给你用）<br>Python：简单、简洁、易学、有效、可扩展性的计算机语言。 最受欢迎的程序语言之一。 强大而丰富的库。<br>C语言：底层，学习成本大。  </p>
<h3 id="6-2-2-Jupyter"><a href="#6-2-2-Jupyter" class="headerlink" title="6.2.2. Jupyter"></a>6.2.2. Jupyter</h3><p>为什么推荐大家使用Jupyter学习和编写Python脚本呢？<br>Jupyter：交互式编程和展示功能。<br>分段执行，编写和测试时边看边写，加快调试速度。<br>能够把运行和输出的结果保存下来，下次打开这个Notebook时也可以看到之前运行的结果。<br>还可以添加各种元素，比如图片、视频、链接等，同时还支持Markdown，可以充当PPT使用。  </p>
<h2 id="6-3-如何"><a href="#6-3-如何" class="headerlink" title="6.3. 如何"></a>6.3. 如何</h2><p>不断解决遇到的疑惑。<br>科技如何给大家带来实效<br>数据的存储对公司有什么影响<br>如何存储数据⇒高效利用 方便对接其他部门和业务<br>如何使用淘宝网上所有绿色产品（如空气净化器）的销量数据来做潜在市场评估<br>如何一直高效率、持续不断地从日新月异的网站中获取信息  </p>
<h3 id="6-3-1-快捷"><a href="#6-3-1-快捷" class="headerlink" title="6.3.1. 快捷"></a>6.3.1. 快捷</h3><p>对初学者来说，使用BeautifulSoup从网页中提取需要的数据更加简单易用。  </p>
<p>谷歌的有效信息检索速度比百度快<br>Stack Overflow上的回答可以比较快地解决问题<br>最新最好的回答很有可能是英文的  </p>
<h3 id="6-3-2-获取动态网页的真实地址"><a href="#6-3-2-获取动态网页的真实地址" class="headerlink" title="6.3.2. 获取动态网页的真实地址"></a>6.3.2. 获取动态网页的真实地址</h3><p>Chrome浏览器的检查（审查元素）功能：浏览器右键⇒检查⇒Network⇒XHR或JS选项<br>Network：显示浏览器从网页服务器中得到的所有文件。一般这些数据以json文件格式获取。<br>在Network选项卡下，找到真正的评论文件。<br>单击Preview标签即可查看数据。可以按 ctrl+F 进行查找。顶部search也可以。<br>Elements会出现相应的code所在的地方。  </p>
<h2 id="6-4-应用场景"><a href="#6-4-应用场景" class="headerlink" title="6.4. 应用场景"></a>6.4. 应用场景</h2><h3 id="6-4-1-爬虫"><a href="#6-4-1-爬虫" class="headerlink" title="6.4.1. 爬虫"></a>6.4.1. 爬虫</h3><p>一些附加值更高的“事”，如人工智能、统计建模等。<br>机器学习和统计算法分析<br>在营销领域可以帮助企业做好4P（Product：产品创新，Place：智能选址，Price：动态价格，Promotion：数据驱动的营销活动）<br>在金融领域，数据驱动的征信等应用会带来越来越大的价值。<br>公开数据的应用价值<br>所有网络数据<br>社交媒体的每一条发帖。社交媒体在用户生态圈的自我交互下产生大量文本、图片和视频数据。<br>团购网站的价格及点评。电商商产品的描述、价格<br>招聘网站的招聘信息<br>搜索引擎从数据库中提取搜索结果  </p>
<h2 id="6-5-注意事项"><a href="#6-5-注意事项" class="headerlink" title="6.5. 注意事项"></a>6.5. 注意事项</h2><p>爬虫有哪些潜在的法律纠纷、公司的爬虫合不合法 。<br>建立共利的互联网环境，不能把爬虫作为窃取数据的工具。<br>爬虫必须在合情、合法、合理的情况下获取和应用。<br>尊重数据供应者的知识产权和正常运作才能产生长久共利的环境。<br>保障对方平台的正常运作是每个程序员都应当做到的<br>法律：<br>互联网世界已经通过自身的协议建立起一定的道德规范（Robots协议）。该协议是国际互联网界通行的道德规范，虽然没有写入法律，但是每一个爬虫都应该遵守这项协议。<br>法律部分还在建立和完善中。<br>如果抓取的数据属于个人使用或科研范畴，基本不存在问题。当你爬取网站数据时，无论是否仅供个人使用，都应该遵守Robots协议。<br>而如果数据属于商业盈利范畴，就要就事而论，有可能属于违法行为，也有可能不违法。<br>大部分网站不欢迎使用程序进行登录，因为需要登录才能查看的数据不属于公开数据。最好不要使用此程序获取非公开数据或批量注册，若出现了问题，可能需负法律责任。  </p>
<p>建议使用API。  </p>
<p>Robots协议<br>Robots协议（爬虫协议）的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。  </p>
<p><a href="https://www.taobao.com/robots.txt。" target="_blank" rel="noopener">https://www.taobao.com/robots.txt。</a><br>Allow开头的URL是允许robot访问的。例如，Allow:/article允许百度爬虫引擎访问/article.htm、/article/12345.com等。<br>Disallow不允许百度爬虫引擎访问的。例如，Disallow:/product/不允许百度爬虫引擎访问/product/12345.com等。<br>Disallow:/禁止百度爬虫访问除了Allow规定页面外的其他所有页面。  </p>
<p>taobao的robots.txt对不同的搜索引擎所允许爬行范围不同。/product项对应淘宝内部的产品信息。当在搜索框中搜索“淘宝iphone7”的时候，Google可搜到淘宝中的产品，而百度不能。  </p>
<p>过于快速或者频密的网络爬虫都会对服务器产生巨大的压力。→调集资源限制爬虫，保护用户的流量和减少有价值数据的流失。  </p>
<p>反爬方维权：网站封锁你IP，法律行动。  </p>
<p>将请求的速度限定在一个合理的范围之内。  </p>
<p>每年的三月份会迎来一个爬虫高峰期。因为有大量的大学生五月份交论文，在写论文的时候会选择爬取数据，也就是3月份爬取数据，4月份分析数据，5月份交论文。  </p>
<p>2007年，爱帮网利用垂直搜索技术获取了大众点评网上的商户简介和消费者点评，并且直接大量使用，大众点评网多次要求爱帮网停止使用这些内容，而爱帮网以自己是使用垂直搜索获得的数据为由，拒绝停止抓取大众点评网上的内容，并且质疑大众点评网对这些内容所享有的著作权。为此，双方开打了两场官司。2011年1月，北京海淀法院做出判决：爱帮网侵犯大众点评网著作权成立，应当停止侵权并赔偿大众点评网经济损失和诉讼必要支出。<br>2013年10月，百度诉360违反Robots协议。百度方面认为，360违反了Robots协议，擅自抓取、复制百度网站内容并生成快照向用户提供。2014年8月7日，北京市第一中级人民法院做出一审判决，法院认为被告奇虎360的行为违反了《反不正当竞争法》相关规定，应赔偿原告百度公司70万元。<br>虽然说大众点评上的点评数据、百度知道的问答由用户创建而非企业，但是搭建平台需要投入运营、技术和人力成本，所以平台拥有对数据的所有权、使用权和分发权。【网站的知识产权】<br>以上两起败诉告诉我们，在爬取网站的时候需要限制自己的爬虫，遵守Robots协议和约束网络爬虫程序的速度。如果违反了这些规定，很可能会吃官司，并且败诉的概率相当高。  </p>
<h1 id="7-多项关系"><a href="#7-多项关系" class="headerlink" title="7. 多项关系"></a>7. 多项关系</h1><h2 id="7-1-流程图"><a href="#7-1-流程图" class="headerlink" title="7.1. 流程图"></a>7.1. 流程图</h2><p>具体步骤及各步骤之间的关系。  </p>
<h3 id="7-1-1-网络爬虫、数据采集"><a href="#7-1-1-网络爬虫、数据采集" class="headerlink" title="7.1.1. 网络爬虫、数据采集"></a>7.1.1. 网络爬虫、数据采集</h3><p>获【取】网页、解【析】网页（提取数据）、【存】储数据、整【理】。  </p>
<ul>
<li>获取网页：给一个网址发送请求，该网址会返回整个网页的数据。类似于在浏览器中键入网址并按回车键，然后可以看到网站的整个页面。  </li>
<li>解析网页：从整个网页的数据中提取想要的数据。类似于在浏览器中看到网站的整个页面，但是你想找的是产品的价格，价格就是你想要的数据。  </li>
<li>存储数据：把数据存储下来。  </li>
</ul>
<p>三个流程的技术实现:  </p>
<ul>
<li>获取网页<br>获取网页的基础技术：request、urllib和selenium（模拟浏览器）。<br>获取网页的进阶技术：多进程多线程抓取、登录抓取、突破IP封禁和服务器抓取。  </li>
<li>解析网页<br>解析网页的基础技术：re正则表达式、BeautifulSoup和lxml。<br>解析网页的进阶技术：解决中文乱码。  </li>
<li>存储数据<br>存储数据的基础技术：存入txt文件和存入csv文件。<br>存储数据的进阶技术：存入MySQL数据库和存入MongoDB数据库。  </li>
</ul>
<h2 id="7-2-分类树"><a href="#7-2-分类树" class="headerlink" title="7.2. 分类树"></a>7.2. 分类树</h2><h2 id="7-3-对比分析"><a href="#7-3-对比分析" class="headerlink" title="7.3. 对比分析"></a>7.3. 对比分析</h2><p>主要的解析器及其优缺点<br><a href="https://res.weread.qq.com/wrepub/epub_928559_44" target="_blank" rel="noopener">https://res.weread.qq.com/wrepub/epub_928559_44</a><br><a href="https://res.weread.qq.com/wrepub/epub_928559_49" target="_blank" rel="noopener">https://res.weread.qq.com/wrepub/epub_928559_49</a><br>使用lxml的解析器将会解析得更快。</p>
<h2 id="7-4-关系图"><a href="#7-4-关系图" class="headerlink" title="7.4. 关系图"></a>7.4. 关系图</h2><p>互联网的运作和结构<br>爬虫程序是收集信息的基础。  </p>
<p>==============================  </p>
<h1 id="8-元学习（与物）"><a href="#8-元学习（与物）" class="headerlink" title="8. 元学习（与物）"></a>8. 元学习（与物）</h1><p>起始、终止、空格和换行，循环次数<br>是啥 为啥 逻辑清晰、循序渐进 查阅此书<br>动其心者，当具有大本大源<br>不断学习新技术，自我提高，实现目标和理想。不断更新和进步：互联网科技、网站信息也随之不断改变。<br>不能应用的技术称为魔术，只能用于表演。<br>学习的道路没有什么捷径可走，唯一的方法就是不断尝试、不断失败、不断改进。<br>通过实战解决实际问题。问题及解决方案实践<br>增强学习效果<br>富有逻辑的框架解构学习。将网络爬虫技术进行框架性的解构<br>认真阅读、手输代码，反复练习，熟能生巧。提升你的编程能力和编程效率<br>从实践中检验自己学习了多少知识<br>进一步巩固<br>进阶问题<br>答案并不是唯一解，对比思路  </p>
<h1 id="9-个人提升（与人）"><a href="#9-个人提升（与人）" class="headerlink" title="9. 个人提升（与人）"></a>9. 个人提升（与人）</h1><p>了解技术团队的运作模式<br>向香港中文大学市场营销学的研究生讲解Python网络爬虫技术，让这些商科学生掌握一些大数据时代重要的技术能力。<br>KYM框架<br>Know Your Company（了解你的公司）<br>Know Your Competitor（了解你的竞争对手）<br>Know Your Customer（了解你的客户）  </p>
<h1 id="10-代码清单"><a href="#10-代码清单" class="headerlink" title="10. 代码清单"></a>10. 代码清单</h1><h2 id="10-1-基础语法"><a href="#10-1-基础语法" class="headerlink" title="10.1. 基础语法"></a>10.1. 基础语法</h2><h3 id="10-1-1-py"><a href="#10-1-1-py" class="headerlink" title="10.1.1. py"></a>10.1.1. py</h3><p>int(number)<br>float(number)<br>for key,value in dict.items()<br>Python 100例 <a href="https://www.w3cschool.cn/python/python-100-examples.html" target="_blank" rel="noopener">https://www.w3cschool.cn/python/python-100-examples.html</a>  </p>
<h4 id="10-1-1-1-类"><a href="#10-1-1-1-类" class="headerlink" title="10.1.1.1. 类"></a>10.1.1.1. 类</h4><pre><code class="py"><span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span>   <span class="comment"># 创建类          </span>
    <span class="function"><span class="keyword">def</span> <span class="title">_init_</span><span class="params">(self,name,age)</span>:</span>  
        <span class="comment"># _init_()方法称为类的构造方法。会自动执行。初始化以及规定传递的参数。self后面的参数列表。实例则传给self  </span>
        <span class="comment"># self 仅在类的定义中使用。表示对整个传递来的对象进行操作。  </span>
        <span class="comment"># 运行时类中self.会自动转为传进来obInstance.进行运算，即self = obInstance【自我理解】  </span>

        self.name = name              
        self.age = age          
    <span class="function"><span class="keyword">def</span> <span class="title">detail</span><span class="params">(self)</span>:</span> <span class="comment">#通过self调用被封装的内容              </span>
        <span class="keyword">print</span> (self.name)              
        <span class="keyword">print</span> (self.age)      

obj1 = Person(<span class="string">'santos'</span>,<span class="number">18</span>)      
obj1.detail()  
<span class="comment"># Python将obj1传给self参数，'santos'和18传给类的构造方法_init_中的name和age  </span>

<span class="comment"># 猫可以：喵喵叫、吃、喝、拉、撒  </span>
<span class="comment"># 狗可以：汪汪叫、吃、喝、拉、撒  </span>

<span class="comment"># 如果用继承的思想，就可以写成：  </span>
<span class="comment"># 动物：吃喝拉撒  </span>
<span class="comment"># 猫：喵喵叫（猫继承动物的功能）  </span>
<span class="comment"># 狗：汪汪叫（狗继承动物的功能）  </span>

<span class="class"><span class="keyword">class</span> <span class="title">Animal</span>:</span>  
    <span class="function"><span class="keyword">def</span> <span class="title">eat</span><span class="params">(self)</span>:</span>  
        <span class="keyword">print</span> (<span class="string">"%s吃 "</span> %self.name)  
    <span class="function"><span class="keyword">def</span> <span class="title">drink</span><span class="params">(self)</span>:</span>  
        <span class="keyword">print</span> (<span class="string">"%s喝 "</span> %self.name)  
    <span class="function"><span class="keyword">def</span> <span class="title">shit</span><span class="params">(self)</span>:</span>  
        <span class="keyword">print</span> (<span class="string">"%s拉 "</span> %self.name)  
    <span class="function"><span class="keyword">def</span> <span class="title">pee</span><span class="params">(self)</span>:</span>  
        <span class="keyword">print</span> (<span class="string">"%s撒 "</span> %self.name)  
<span class="class"><span class="keyword">class</span> <span class="title">Cat</span><span class="params">(Animal)</span>:</span>  
    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name)</span>:</span>  
        self.name = name  
    <span class="function"><span class="keyword">def</span> <span class="title">cry</span><span class="params">(self)</span>:</span>  
        <span class="keyword">print</span> (<span class="string">'喵喵叫'</span>)  
<span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(Animal)</span>:</span>  
    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name)</span>:</span>  
        self.name = name  
    <span class="function"><span class="keyword">def</span> <span class="title">cry</span><span class="params">(self)</span>:</span>  
        <span class="keyword">print</span> (<span class="string">'汪汪叫'</span>)  
c1 = Cat(<span class="string">'小白家的小黑猫'</span>)  
c1.eat()  
c1.cry()  
d1 = Dog(<span class="string">'胖子家的小瘦狗'</span>)  
d1.eat()  

<span class="comment"># 小白家的小黑猫吃  </span>
<span class="comment"># 喵喵叫  </span>
<span class="comment"># 胖子家的小瘦狗吃  </span></code></pre>
<h3 id="10-1-2-函数、类，可变与不可变"><a href="#10-1-2-函数、类，可变与不可变" class="headerlink" title="10.1.2. 函数、类，可变与不可变"></a>10.1.2. 函数、类，可变与不可变</h3><pre><code class="py">a = <span class="number">1</span>  
<span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a)</span>:</span>  
    a = <span class="number">2</span>  
fun(a)  
<span class="keyword">print</span> (a)  
&gt;&gt;&gt;<span class="number">1</span>  

a为数字int，函数改变不了函数以外a的值。当一个引用传递给函数时，函数自动复制一份引用。函数里和函数外的引用是不一样的。  



a = []  
<span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a)</span>:</span>  
    a.append(<span class="number">1</span>)  
fun(a)  
<span class="keyword">print</span> (a)  
&gt;&gt;&gt;[<span class="number">1</span>]  
a为列表，函数将函数以外的a值改变了。函数内的引用指向的是可变对象列表a，函数内的列表a和函数外的列表a是同一个。  
<span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span>  
    name=<span class="string">"aaa"</span>  

p1=Person()  
p2=Person()  
p1.name=<span class="string">"bbb"</span>  
<span class="keyword">print</span> (p1.name)  
<span class="keyword">print</span> (p2.name)  
<span class="keyword">print</span> (Person.name)  

&gt;&gt;&gt;bbb  
&gt;&gt;&gt;aaa  
&gt;&gt;&gt;aaa  
p1.name=<span class="string">"bbb"</span>表示实例调用了类变量，其实就是函数传参的问题。p1.name一开始指向类变量name=<span class="string">"aaa"</span>，但是在实例的作用域里把类变量的引用改变了，就变成了一个实例变量，self.name不再引用Person的类变量name了。  
<span class="class"><span class="keyword">class</span> <span class="title">Person</span>:</span>  
    name=[]  

p1=Person()  
p2=Person()  
p1.name.append(<span class="number">1</span>)  
<span class="keyword">print</span> (p1.name)  
<span class="keyword">print</span> (p2.name)  
<span class="keyword">print</span> (Person.name)  
&gt;&gt;&gt;[<span class="number">1</span>]  
&gt;&gt;&gt;[<span class="number">1</span>]  
&gt;&gt;&gt;[<span class="number">1</span>]  
!类中的可变量的慎重使用！！！！！！！！！！！！！！！ist、dict等是可更改对象，因此修改一个指向的对象时会把类变量也改变了。  </code></pre>
<h2 id="10-2-基础算法"><a href="#10-2-基础算法" class="headerlink" title="10.2. 基础算法"></a>10.2. 基础算法</h2><h3 id="10-2-1-循环打印输出从1到100的所有奇数"><a href="#10-2-1-循环打印输出从1到100的所有奇数" class="headerlink" title="10.2.1. 循环打印输出从1到100的所有奇数"></a>10.2.1. 循环打印输出从1到100的所有奇数</h3><pre><code class="py"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">101</span>):  
    <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">1</span>:  
        <span class="keyword">print</span> (i)  </code></pre>
<h3 id="10-2-2-字符串批量替换"><a href="#10-2-2-字符串批量替换" class="headerlink" title="10.2.2. 字符串批量替换"></a>10.2.2. 字符串批量替换</h3><p>请将字符串“你好$$$我正在学Python@#@#现在需要&amp;<em>&amp;</em>&amp;修改字符串”中的符号变成一个空格，需要输出的格式为：“你好 我正在学Python现在需要 修改字符串”。  </p>
<pre><code class="py"><span class="comment"># 方法1  </span>
str1 = <span class="string">'你好$$$我正在学Python@#@#现在需要&amp;%&amp;%&amp;修改字符串'</span>  
str2 = str1.replace(<span class="string">'$$$'</span>, <span class="string">' '</span>).replace(<span class="string">'@#@#'</span>, <span class="string">' '</span>).replace(<span class="string">'&amp;%&amp;%&amp;'</span>, <span class="string">' '</span>)  
<span class="keyword">print</span> (str2)  
<span class="comment"># 方法2  </span>
<span class="keyword">import</span> re  
str1 = <span class="string">'你好$$$我正在学Python@#@#现在需要&amp;%&amp;%&amp;修改字符串'</span>  
str2 = re.sub(<span class="string">'[$@#&amp;%]+'</span>, <span class="string">' '</span> ,str1)  
<span class="keyword">print</span> (str2)  </code></pre>
<h3 id="10-2-3-输出9×9乘法口诀表"><a href="#10-2-3-输出9×9乘法口诀表" class="headerlink" title="10.2.3. 输出9×9乘法口诀表"></a>10.2.3. 输出9×9乘法口诀表</h3><pre><code class="py"><span class="comment"># 此法会有多余的换行和末尾对于的空格  </span>
<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">10</span>):  
    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,i+<span class="number">1</span>):  
        print(<span class="string">'{}×{}={}'</span>.format(j,i,j*i),end=<span class="string">' '</span>)  
    print(<span class="string">'\n'</span>)  

<span class="comment"># 更好的方法，没有对齐  </span>

<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">10</span>):  
    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,i+<span class="number">1</span>):  
        print(<span class="string">'{}×{}={} '</span>.format(j,i,j*i),end=<span class="string">''</span>)  
    print(<span class="string">''</span>)  

<span class="comment"># 最好的方法 这里是对齐的。由此可见，'\t'是用来【显示】对齐的，但似乎len就是1  </span>
<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">10</span>):  
    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,i+<span class="number">1</span>):  
        print(<span class="string">'{}×{}={}\t'</span>.format(j,i,j*i),end=<span class="string">''</span>)  
    print(<span class="string">''</span>)  

<span class="comment"># 最好的方法 这里是对齐的  </span>
<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">10</span>):  
    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, i+<span class="number">1</span>):  
        <span class="keyword">print</span> (<span class="string">"%dx%d=%d\t"</span> % (j, i, i*j), end=<span class="string">""</span>)  
    print(<span class="string">""</span>)  

<span class="comment"># 1×1=1  </span>

<span class="comment"># 1×2=2 2×2=4  </span>

<span class="comment"># 1×3=3 2×3=6 3×3=9  </span>

<span class="comment"># 1×4=4 2×4=8 3×4=12 4×4=16  </span>

<span class="comment"># 1×5=5 2×5=10 3×5=15 4×5=20 5×5=25   </span>

<span class="comment"># 1×6=6 2×6=12 3×6=18 4×6=24 5×6=30 6×6=36  </span>

<span class="comment"># 1×7=7 2×7=14 3×7=21 4×7=28 5×7=35 6×7=42 7×7=49  </span>

<span class="comment"># 1×8=8 2×8=16 3×8=24 4×8=32 5×8=40 6×8=48 7×8=56 8×8=64  </span>

<span class="comment"># 1×9=9 2×9=18 3×9=27 4×9=36 5×9=45 6×9=54 7×9=63 8×9=72 9×9=81  </span>

<span class="comment"># 1×1=1  </span>
<span class="comment"># 1×2=2 2×2=4  </span>
<span class="comment"># 1×3=3 2×3=6 3×3=9  </span>
<span class="comment"># 1×4=4 2×4=8 3×4=12 4×4=16  </span>
<span class="comment"># 1×5=5 2×5=10 3×5=15 4×5=20 5×5=25  </span>
<span class="comment"># 1×6=6 2×6=12 3×6=18 4×6=24 5×6=30 6×6=36  </span>
<span class="comment"># 1×7=7 2×7=14 3×7=21 4×7=28 5×7=35 6×7=42 7×7=49  </span>
<span class="comment"># 1×8=8 2×8=16 3×8=24 4×8=32 5×8=40 6×8=48 7×8=56 8×8=64  </span>
<span class="comment"># 1×9=9 2×9=18 3×9=27 4×9=36 5×9=45 6×9=54 7×9=63 8×9=72 9×9=81  </span>
<span class="comment"># 1×1=1  </span>
<span class="comment"># 1×2=2   2×2=4  </span>
<span class="comment"># 1×3=3   2×3=6   3×3=9  </span>
<span class="comment"># 1×4=4   2×4=8   3×4=12  4×4=16  </span>
<span class="comment"># 1×5=5   2×5=10  3×5=15  4×5=20  5×5=25  </span>
<span class="comment"># 1×6=6   2×6=12  3×6=18  4×6=24  5×6=30  6×6=36  </span>
<span class="comment"># 1×7=7   2×7=14  3×7=21  4×7=28  5×7=35  6×7=42  7×7=49  </span>
<span class="comment"># 1×8=8   2×8=16  3×8=24  4×8=32  5×8=40  6×8=48  7×8=56  8×8=64  </span>
<span class="comment"># 1×9=9   2×9=18  3×9=27  4×9=36  5×9=45  6×9=54  7×9=63  8×9=72  9×9=81  </span>
<span class="comment"># 1x1=1  </span>
<span class="comment"># 1x2=2   2x2=4  </span>
<span class="comment"># 1x3=3   2x3=6   3x3=9  </span>
<span class="comment"># 1x4=4   2x4=8   3x4=12  4x4=16  </span>
<span class="comment"># 1x5=5   2x5=10  3x5=15  4x5=20  5x5=25  </span>
<span class="comment"># 1x6=6   2x6=12  3x6=18  4x6=24  5x6=30  6x6=36  </span>
<span class="comment"># 1x7=7   2x7=14  3x7=21  4x7=28  5x7=35  6x7=42  7x7=49  </span>
<span class="comment"># 1x8=8   2x8=16  3x8=24  4x8=32  5x8=40  6x8=48  7x8=56  8x8=64  </span>
<span class="comment"># 1x9=9   2x9=18  3x9=27  4x9=36  5x9=45  6x9=54  7x9=63  8x9=72  9x9=81  </span>

print(len(<span class="string">'{}\t'</span>.format(<span class="number">5</span>*<span class="number">6</span>)))  
print(len(<span class="string">'{}\t'</span>.format(<span class="number">5</span>*<span class="number">60</span>)))  
print(len(<span class="string">'{}\t'</span>.format(<span class="number">5</span>*<span class="number">600</span>)))  
print(len(<span class="string">'{}\t'</span>.format(<span class="number">5</span>*<span class="number">6000</span>)))  

<span class="comment"># 3  </span>
<span class="comment"># 4  </span>
<span class="comment"># 5  </span>
<span class="comment"># 6  </span></code></pre>
<h3 id="10-2-4-利润分段计算"><a href="#10-2-4-利润分段计算" class="headerlink" title="10.2.4. 利润分段计算"></a>10.2.4. 利润分段计算</h3><p>请写出一个函数，当输入函数变量月利润为I时，能返回应发放奖金的总数。例如，输出“利润为100000元时，应发放奖金总数为10000元”。<br>其中，企业发放的奖金根据利润提成。<br>利润（I）低于或等于10万元时，奖金可提10%；<br>利润高于10万元，低于20万元时，低于10万元的部分按10%提成，高于10万元的部分，可提成7.5%；<br>利润在20万元到40万元之间时，高于20万元的部分可提成5%；<br>利润在40万元到60万元之间时，高于40万元的部分可提成3%；<br>利润在60万元到100万元之间时，高于60万元的部分可提成1.5%；<br>利润高于100万元时，超过100万元的部分按1%提成。  </p>
<pre><code class="py"><span class="function"><span class="keyword">def</span> <span class="title">calcute_profit</span><span class="params">(I)</span>:</span>  
    I = I / <span class="number">10000</span>  
    <span class="keyword">if</span> I &lt;= <span class="number">10</span>:  
        a = I * <span class="number">0.01</span>  
        <span class="keyword">return</span> a * <span class="number">10000</span>  
    <span class="keyword">elif</span> I &lt;= <span class="number">20</span> <span class="keyword">and</span> I &gt; <span class="number">10</span>:  
        b =<span class="number">0.25</span> + I * <span class="number">0.075</span>  
        <span class="keyword">return</span> b * <span class="number">10000</span>  
    <span class="keyword">elif</span> I &lt;= <span class="number">40</span> <span class="keyword">and</span> I &gt; <span class="number">20</span>:  
        c = <span class="number">0.75</span> + I * <span class="number">0.05</span>  
        <span class="keyword">return</span> c * <span class="number">10000</span>  
    <span class="keyword">elif</span> I &lt;= <span class="number">60</span> <span class="keyword">and</span> I &gt; <span class="number">40</span>:  
        d = <span class="number">0.95</span> + I * <span class="number">0.03</span>  
        <span class="keyword">return</span> d * <span class="number">10000</span>  
    <span class="keyword">elif</span> I &lt;= <span class="number">60</span> <span class="keyword">and</span> I &gt; <span class="number">100</span>:  
        e = <span class="number">2</span> + I * <span class="number">0.015</span>  
        <span class="keyword">return</span> e * <span class="number">10000</span>  
    <span class="keyword">else</span>:  
        f = <span class="number">2.95</span> + I * <span class="number">0.01</span>  
        <span class="keyword">return</span> f * <span class="number">10000</span>  

I = int(input(<span class="string">'净利润:'</span>))  
profit = calcute_profit(I)  
<span class="keyword">print</span> (<span class="string">'利润为%d元时，应发奖金总数为%d元'</span> % (I, profit))  

<span class="function"><span class="keyword">def</span> <span class="title">calcute_profit</span><span class="params">(I)</span>:</span>  
    arr = [<span class="number">1000000</span>,<span class="number">600000</span>,<span class="number">400000</span>,<span class="number">200000</span>,<span class="number">100000</span>,<span class="number">0</span>] <span class="comment">#这应该就是各个分界值了，把它们放在列表里方便访问  </span>
    rat = [<span class="number">0.01</span>,<span class="number">0.015</span>,<span class="number">0.03</span>,<span class="number">0.05</span>,<span class="number">0.075</span>,<span class="number">0.1</span>] <span class="comment">#这是各个分界值所对应的奖金比例值  </span>
    r = <span class="number">0</span>                       <span class="comment">#这是总奖金的初始值  </span>
    <span class="keyword">for</span> idx <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">6</span>):      <span class="comment">#有6个分界值当然要循环6次  </span>
        <span class="keyword">if</span> I &gt; arr[idx]:  
            r = r + (I - arr[idx]) * rat[idx]  
            I = arr[idx]  
    <span class="keyword">return</span> r  

I = int(input(<span class="string">'净利润:'</span>))  
profit = calcute_profit(I)  
<span class="keyword">print</span> (<span class="string">'利润为%d元时，应发奖金总数为%d元'</span> % (I, profit))  </code></pre>
<h3 id="10-2-5-字典排序"><a href="#10-2-5-字典排序" class="headerlink" title="10.2.5. 字典排序"></a>10.2.5. 字典排序</h3><p>用字典的值对字典进行排序，将{1: 2, 3: 4, 4:3, 2:1, 0:0}按照字典的值从大到小进行排序。  </p>
<pre><code class="py"><span class="keyword">import</span> operator  
x = {<span class="number">1</span>: <span class="number">2</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>:<span class="number">3</span>, <span class="number">2</span>:<span class="number">1</span>, <span class="number">0</span>:<span class="number">0</span>}  
sorted_x = sorted(x.items(), key=operator.itemgetter(<span class="number">1</span>))  
<span class="keyword">print</span> (sorted_x)  </code></pre>
<p>[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]<br>对字典进行排序是【不可能】的，只有把字典【转换】成另一种方式才能排序。字典本身是无序的，但是如列表元组等其他类型是有序的，所以需要用一个元组列表来表示排序的字典。  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/en/2023/12/25/Python%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84/" data-id="ck4lrulmz000q04vx1vww59oz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/en/tags/%E4%BD%93%E7%B3%BB/" rel="tag">体系</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/en/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>

    </footer>
  </div>
  
  
<nav id="article-nav">
  
  
    <a href="/en/2020/12/25/Flask%E8%AF%AD%E6%B3%95%E9%87%8A%E4%B9%89/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Flask语法释义</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/en/categories/Diary/">Diary</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/en/categories/Diary/Games/">Games</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/en/categories/Diary/PlayStation/">PlayStation</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/en/categories/Life/">Life</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/Flask/" rel="tag">Flask</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/%E4%BD%93%E7%B3%BB/" rel="tag">体系</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/%E5%90%8E%E7%BB%AD%E5%AD%A6%E4%B9%A0/" rel="tag">后续学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" rel="tag">知识整理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag">读书笔记</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/en/tags/%E8%B5%84%E6%BA%90/" rel="tag">资源</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/en/tags/Flask/" style="font-size: 10px;">Flask</a> <a href="/en/tags/%E4%BD%93%E7%B3%BB/" style="font-size: 10px;">体系</a> <a href="/en/tags/%E5%90%8E%E7%BB%AD%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">后续学习</a> <a href="/en/tags/%E7%88%AC%E8%99%AB/" style="font-size: 10px;">爬虫</a> <a href="/en/tags/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/" style="font-size: 10px;">知识整理</a> <a href="/en/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">读书笔记</a> <a href="/en/tags/%E8%B5%84%E6%BA%90/" style="font-size: 10px;">资源</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2023/12/">十二月 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2020/12/">十二月 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/en/archives/2019/12/">十二月 2019</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/en/2023/12/25/Python%E7%88%AC%E8%99%AB%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84/">Python爬虫知识结构</a>
          </li>
        
          <li>
            <a href="/en/2020/12/25/Flask%E8%AF%AD%E6%B3%95%E9%87%8A%E4%B9%89/">Flask语法释义</a>
          </li>
        
          <li>
            <a href="/en/2020/12/25/cs_learning_path/">cs_learning_path</a>
          </li>
        
          <li>
            <a href="/en/2019/12/26/python%E7%9A%84%E7%89%B9%E6%AE%8A%E6%96%B9%E6%B3%95/">python的特殊方法</a>
          </li>
        
          <li>
            <a href="/en/2019/12/26/packtpub/">packtpub</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 CJ<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/en/" class="mobile-nav-link">Home</a>
  
    <a href="/en/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/en/fancybox/jquery.fancybox.css">

  
<script src="/en/fancybox/jquery.fancybox.pack.js"></script>




<script src="/en/js/script.js"></script>




  </div>
</body>
</html>